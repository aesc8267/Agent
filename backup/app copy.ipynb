{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent,DuckDuckGoSearchTool, HfApiModel,load_tool,tool\n",
    "import datetime\n",
    "import requests\n",
    "import pytz\n",
    "import yaml\n",
    "from tools.final_answer import FinalAnswerTool\n",
    "from tools.visit_webpage import VisitWebpageTool\n",
    "\n",
    "# from Gradio_UI import GradioUI\n",
    "\n",
    "# Below is an example of a tool that does nothing. Amaze us with your creativity !\n",
    "@tool\n",
    "def my_custom_tool(arg1:str, arg2:int)-> str: #it's import to specify the return type\n",
    "    #Keep this format for the description / args / args description but feel free to modify the tool\n",
    "    \"\"\"A tool that does nothing yet \n",
    "    Args:\n",
    "        arg1: the first argument\n",
    "        arg2: the second argument\n",
    "    \"\"\"\n",
    "    return \"What magic will you build ?\"\n",
    "\n",
    "@tool\n",
    "def get_current_time_in_timezone(timezone: str) -> str:\n",
    "    \"\"\"A tool that fetches the current local time in a specified timezone.\n",
    "    Args:\n",
    "        timezone: A string representing a valid timezone (e.g., 'America/New_York').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create timezone object\n",
    "        tz = pytz.timezone(timezone)\n",
    "        # Get current time in that timezone\n",
    "        local_time = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {timezone} is: {local_time}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching time for timezone '{timezone}': {str(e)}\"\n",
    "\n",
    "\n",
    "final_answer = FinalAnswerTool()\n",
    "visit_webpage = VisitWebpageTool()\n",
    "# If the agent does not answer, the model is overloaded, please use another model or the following Hugging Face Endpoint that also contains qwen2.5 coder:\n",
    "# model_id='https://pflgm2locj2t89co.us-east-1.aws.endpoints.huggingface.cloud' \n",
    "\n",
    "model = HfApiModel(\n",
    "max_tokens=2096,\n",
    "temperature=0.5,\n",
    "# model_id='Qwen/Qwen2.5-Coder-32B-Instruct',# it is possible that this model may be overloaded\n",
    "model_id='https://pflgm2locj2t89co.us-east-1.aws.endpoints.huggingface.cloud',\n",
    "custom_role_conversions=None,\n",
    ")\n",
    "\n",
    "\n",
    "# Import tool from Hub\n",
    "image_generation_tool = load_tool(\"agents-course/text-to-image\", trust_remote_code=True)\n",
    "\n",
    "with open(\"prompts.yaml\", 'r') as stream:\n",
    "    prompt_templates = yaml.safe_load(stream)\n",
    "    \n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[visit_webpage,image_generation_tool,final_answer], ## add your tools here (don't remove final answer)\n",
    "    max_steps=6,\n",
    "    verbosity_level=1,\n",
    "    grammar=None,\n",
    "    planning_interval=None,\n",
    "    name=None,\n",
    "    description=None,\n",
    "    prompt_templates=prompt_templates\n",
    ")\n",
    "\n",
    "\n",
    "# GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents.agent_types import AgentAudio, AgentImage, AgentText, handle_agent_output_types\n",
    "from smolagents.agents import ActionStep, MultiStepAgent\n",
    "from smolagents.memory import MemoryStep\n",
    "from smolagents.utils import _is_package_available\n",
    "from typing import Optional\n",
    "def stream_to_gradio(\n",
    "    agent,\n",
    "    task: str,\n",
    "    reset_agent_memory: bool = False,\n",
    "    additional_args: Optional[dict] = None,\n",
    "):\n",
    "    \"\"\"Runs an agent with the given task and streams the messages from the agent as gradio ChatMessages.\"\"\"\n",
    "    if not _is_package_available(\"gradio\"):\n",
    "        raise ModuleNotFoundError(\n",
    "            \"Please install 'gradio' extra to use the GradioUI: `pip install 'smolagents[gradio]'`\"\n",
    "        )\n",
    "    import gradio as gr\n",
    "\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "\n",
    "    for step_log in agent.run(task, stream=True, reset=reset_agent_memory, additional_args=additional_args):\n",
    "        # Track tokens if model provides them\n",
    "        if hasattr(agent.model, \"last_input_token_count\"):\n",
    "            total_input_tokens += agent.model.last_input_token_count\n",
    "            total_output_tokens += agent.model.last_output_token_count\n",
    "            if isinstance(step_log, ActionStep):\n",
    "                step_log.input_token_count = agent.model.last_input_token_count\n",
    "                step_log.output_token_count = agent.model.last_output_token_count\n",
    "\n",
    "        for message in pull_messages_from_step(\n",
    "            step_log,\n",
    "        ):\n",
    "            yield message\n",
    "\n",
    "    final_answer = step_log  # Last log is the run's final_answer\n",
    "    final_answer = handle_agent_output_types(final_answer)\n",
    "\n",
    "    if isinstance(final_answer, AgentText):\n",
    "        yield gr.ChatMessage(\n",
    "            role=\"assistant\",\n",
    "            content=f\"**Final answer:**\\n{final_answer.to_string()}\\n\",\n",
    "        )\n",
    "    elif isinstance(final_answer, AgentImage):\n",
    "        yield gr.ChatMessage(\n",
    "            role=\"assistant\",\n",
    "            content={\"path\": final_answer.to_string(), \"mime_type\": \"image/png\"},\n",
    "        )\n",
    "    elif isinstance(final_answer, AgentAudio):\n",
    "        yield gr.ChatMessage(\n",
    "            role=\"assistant\",\n",
    "            content={\"path\": final_answer.to_string(), \"mime_type\": \"audio/wav\"},\n",
    "        )\n",
    "    else:\n",
    "        yield gr.ChatMessage(role=\"assistant\", content=f\"**Final answer:** {str(final_answer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_messages_from_step(\n",
    "    step_log: MemoryStep,\n",
    "):\n",
    "    \"\"\"Extract ChatMessage objects from agent steps with proper nesting\"\"\"\n",
    "    import gradio as gr\n",
    "\n",
    "    if isinstance(step_log, ActionStep):\n",
    "        # Output the step number\n",
    "        step_number = f\"Step {step_log.step_number}\" if step_log.step_number is not None else \"\"\n",
    "        yield gr.ChatMessage(role=\"assistant\", content=f\"**{step_number}**\")\n",
    "\n",
    "        # First yield the thought/reasoning from the LLM\n",
    "        if hasattr(step_log, \"model_output\") and step_log.model_output is not None:\n",
    "            # Clean up the LLM output\n",
    "            model_output = step_log.model_output.strip()\n",
    "            # Remove any trailing <end_code> and extra backticks, handling multiple possible formats\n",
    "            model_output = re.sub(r\"```\\s*<end_code>\", \"```\", model_output)  # handles ```<end_code>\n",
    "            model_output = re.sub(r\"<end_code>\\s*```\", \"```\", model_output)  # handles <end_code>```\n",
    "            model_output = re.sub(r\"```\\s*\\n\\s*<end_code>\", \"```\", model_output)  # handles ```\\n<end_code>\n",
    "            model_output = model_output.strip()\n",
    "            yield gr.ChatMessage(role=\"assistant\", content=model_output)\n",
    "\n",
    "        # For tool calls, create a parent message\n",
    "        if hasattr(step_log, \"tool_calls\") and step_log.tool_calls is not None:\n",
    "            first_tool_call = step_log.tool_calls[0]\n",
    "            used_code = first_tool_call.name == \"python_interpreter\"\n",
    "            parent_id = f\"call_{len(step_log.tool_calls)}\"\n",
    "\n",
    "            # Tool call becomes the parent message with timing info\n",
    "            # First we will handle arguments based on type\n",
    "            args = first_tool_call.arguments\n",
    "            if isinstance(args, dict):\n",
    "                content = str(args.get(\"answer\", str(args)))\n",
    "            else:\n",
    "                content = str(args).strip()\n",
    "\n",
    "            if used_code:\n",
    "                # Clean up the content by removing any end code tags\n",
    "                content = re.sub(r\"```.*?\\n\", \"\", content)  # Remove existing code blocks\n",
    "                content = re.sub(r\"\\s*<end_code>\\s*\", \"\", content)  # Remove end_code tags\n",
    "                content = content.strip()\n",
    "                if not content.startswith(\"```python\"):\n",
    "                    content = f\"```python\\n{content}\\n```\"\n",
    "\n",
    "            parent_message_tool = gr.ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=content,\n",
    "                metadata={\n",
    "                    \"title\": f\"üõ†Ô∏è Used tool {first_tool_call.name}\",\n",
    "                    \"id\": parent_id,\n",
    "                    \"status\": \"pending\",\n",
    "                },\n",
    "            )\n",
    "            yield parent_message_tool\n",
    "\n",
    "            # Nesting execution logs under the tool call if they exist\n",
    "            if hasattr(step_log, \"observations\") and (\n",
    "                step_log.observations is not None and step_log.observations.strip()\n",
    "            ):  # Only yield execution logs if there's actual content\n",
    "                log_content = step_log.observations.strip()\n",
    "                if log_content:\n",
    "                    log_content = re.sub(r\"^Execution logs:\\s*\", \"\", log_content)\n",
    "                    yield gr.ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=f\"{log_content}\",\n",
    "                        metadata={\"title\": \"üìù Execution Logs\", \"parent_id\": parent_id, \"status\": \"done\"},\n",
    "                    )\n",
    "\n",
    "            # Nesting any errors under the tool call\n",
    "            if hasattr(step_log, \"error\") and step_log.error is not None:\n",
    "                yield gr.ChatMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=str(step_log.error),\n",
    "                    metadata={\"title\": \"üí• Error\", \"parent_id\": parent_id, \"status\": \"done\"},\n",
    "                )\n",
    "\n",
    "            # Update parent message metadata to done status without yielding a new message\n",
    "            parent_message_tool.metadata[\"status\"] = \"done\"\n",
    "\n",
    "        # Handle standalone errors but not from tool calls\n",
    "        elif hasattr(step_log, \"error\") and step_log.error is not None:\n",
    "            yield gr.ChatMessage(role=\"assistant\", content=str(step_log.error), metadata={\"title\": \"üí• Error\"})\n",
    "\n",
    "        # Calculate duration and token information\n",
    "        step_footnote = f\"{step_number}\"\n",
    "        if hasattr(step_log, \"input_token_count\") and hasattr(step_log, \"output_token_count\"):\n",
    "            token_str = (\n",
    "                f\" | Input-tokens:{step_log.input_token_count:,} | Output-tokens:{step_log.output_token_count:,}\"\n",
    "            )\n",
    "            step_footnote += token_str\n",
    "        if hasattr(step_log, \"duration\"):\n",
    "            step_duration = f\" | Duration: {round(float(step_log.duration), 2)}\" if step_log.duration else None\n",
    "            step_footnote += step_duration\n",
    "        step_footnote = f\"\"\"<span style=\"color: #bbbbc2; font-size: 12px;\">{step_footnote}</span> \"\"\"\n",
    "        yield gr.ChatMessage(role=\"assistant\", content=f\"{step_footnote}\")\n",
    "        yield gr.ChatMessage(role=\"assistant\", content=\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meassages=[]\n",
    "for msg in stream_to_gradio(agent, \"plz tell me the main information in this website 'https://github.com/huggingface/diffusers'\"):\n",
    "    meassages.append(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

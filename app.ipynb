{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent,OpenAIServerModel,tool,HfApiModel,DuckDuckGoSearchTool\n",
    "model=OpenAIServerModel(model_id='deepseek-r1',api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",api_key=\"sk-615616fb539749dda57c80cc0928669d\")\n",
    "# model = HfApiModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('prompts.yaml','r') as stream:\n",
    "    prompt_templates=yaml.safe_load(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aesc\\AppData\\Local\\Temp\\ipykernel_4808\\2312888540.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectordb=FAISS.load_local(\"./vectordb\",embeddings=HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\"),allow_dangerous_deserialization=True)\n",
      "e:\\Anaconda\\envs\\agent\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aesc\\.cache\\huggingface\\hub\\models--thenlper--gte-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#使用rag\n",
    "from langchain.vectorstores import FAISS\n",
    "from tools.Retriever_tool import RetrieverTool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "vectordb=FAISS.load_local(\"./vectordb\",embeddings=HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\"),allow_dangerous_deserialization=True)\n",
    "retrievertool=RetrieverTool(vectordb=vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.final_answer import FinalAnswerTool\n",
    "from tools.vision_comprehension import VisionComprehension\n",
    "from tools.file_io import file_writer\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[DuckDuckGoSearchTool(), file_writer(), FinalAnswerTool(), retrievertool],\n",
    "    additional_authorized_imports=[\n",
    "        \"flask\",\n",
    "        \"os\",\n",
    "        \"matplotlib\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "        \"seaborn\",\n",
    "        \"sklearn\",\n",
    "        \"torch\",\n",
    "        \"transformers\",\n",
    "        \"tensorflow\",\n",
    "        \"keras\",\n",
    "        \"cv2\",\n",
    "        \"PIL\",\n",
    "        \"matplotlib.pyplot\",\n",
    "        \"matplotlib.pyplot as plt\",\n",
    "        \"pandas as pd\",\n",
    "        \"numpy as np\",\n",
    "        \"seaborn as sns\",\n",
    "        \"sklearn as sk\",\n",
    "        \"torch as torch\",\n",
    "        \"transformers as transformers\",\n",
    "        \"tensorflow as tf\",\n",
    "        \"keras as keras\",\n",
    "        \"cv2 as cv2\",\n",
    "        \"PIL as PIL\",\n",
    "        \"matplotlib.pyplot as plt\",\n",
    "        \"matplotlib.pyplot as plt\",\n",
    "        \"pandas as pd\",\n",
    "        \"numpy as np\",\n",
    "        \"seaborn as sns\",\n",
    "        \"sklearn as sk\",\n",
    "        \"torch as torch\",\n",
    "        \"transformers as transformers\",\n",
    "        \"tensorflow as tf\",\n",
    "        \"keras as keras\",\n",
    "        \"cv2 as cv2\",\n",
    "        \"PIL as PIL\",\n",
    "    ],\n",
    "    prompt_templates=prompt_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m这是一个数据分析任务,对于这个任务你需要分步来完成，所以对于管理agent首先你需要规划好整个流程，每一步需要怎么做，如有需要请利用检索agent检索信息。具体任务：\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/esca/Desktop/Agent/data/anime-dataset-2023.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 这是一个与动漫相关的数据集，请自由发挥，进行数据挖掘，帮我写一份数据分析报告,要求理解数据分析内容并展开讨论,你需要保存必要的图表在\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./outputs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 目录，然后允许你将最后的分析内容写成一个markdown文件使用tool保存下来，分析内容使用中文\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"这是一个数据分析任务,对于这个任务你需要分步来完成，所以对于管理agent首先你需要规划好整个流程，每一步需要怎么做，如有需要请利用检索agent检索信息。具体任务：'/Users/esca/Desktop/Agent/data/anime-dataset-2023.csv' 这是一个与动漫相关的数据集，请自由发挥，进行数据挖掘，帮我写一份数据分析报告,要求理解数据分析内容并展开讨论,你需要保存必要的图表在'./outputs' 目录，然后允许你将最后的分析内容写成一个markdown文件使用tool保存下来，分析内容使用中文\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
